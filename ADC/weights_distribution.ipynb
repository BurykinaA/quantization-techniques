{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from ADC.models import MLP, MLPADC, MLPQuant, MLPADCAshift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for model loading (if applicable): cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for model loading (if applicable): {device}\")\n",
    "\n",
    "RESULTS_DIR = './results'\n",
    "PLOTS_OUTPUT_DIR = os.path.join(RESULTS_DIR, 'weight_distributions')\n",
    "os.makedirs(PLOTS_OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model_instance_and_params(filename_key):\n",
    "#     \"\"\"\n",
    "#     Parses the filename key to determine model type and parameters,\n",
    "#     then instantiates the model.\n",
    "#     \"\"\"\n",
    "#     params = {}\n",
    "#     model_type_str = None\n",
    "    \n",
    "#     # The filename_key is the part of the filename like \"MLPADC_bx8_bw8_ba8_k4\"\n",
    "#     # Order of regex matching is important: more specific patterns first.\n",
    "#     # We use re.fullmatch to ensure the entire key string matches the pattern.\n",
    "\n",
    "#     # MLPADCAshift+W-Reshape\n",
    "#     # Example: MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.001\n",
    "#     match = re.fullmatch(r\"MLPADCAshiftplusW-Reshape_ashift(True|False)_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)lk([\\d.]+)\", filename_key)\n",
    "#     if match:\n",
    "#         model_type_str = \"MLPADCAshift\"\n",
    "#         params['ashift_enabled'] = match.group(1) == \"True\"\n",
    "#         params['bx'] = int(match.group(2))\n",
    "#         params['bw'] = int(match.group(3))\n",
    "#         params['ba'] = int(match.group(4))\n",
    "#         params['k'] = int(match.group(5))\n",
    "#         # lk (lambda_kurtosis) is a training param, not model architecture\n",
    "        \n",
    "#     # MLPADCAshift (no W-Reshape)\n",
    "#     # Example: MLPADCAshift_ashiftTrue_bx8bw8ba8k4\n",
    "#     if not model_type_str:\n",
    "#         match = re.fullmatch(r\"MLPADCAshift_ashift(True|False)_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)\", filename_key)\n",
    "#         if match:\n",
    "#             model_type_str = \"MLPADCAshift\"\n",
    "#             params['ashift_enabled'] = match.group(1) == \"True\"\n",
    "#             params['bx'] = int(match.group(2))\n",
    "#             params['bw'] = int(match.group(3))\n",
    "#             params['ba'] = int(match.group(4))\n",
    "#             params['k'] = int(match.group(5))\n",
    "\n",
    "#     # MLPADC+W-Reshape\n",
    "#     # Example: MLPADCplusW-Reshape_bx8_bw8_ba8_k4_lk0.001\n",
    "#     if not model_type_str:\n",
    "#         match = re.fullmatch(r\"MLPADCplusW-Reshape_bx(\\d+)_bw(\\d+)_ba(\\d+)_k(\\d+)_lk([\\d.]+)\", filename_key)\n",
    "#         if match:\n",
    "#             model_type_str = \"MLPADC\"\n",
    "#             params['bx'] = int(match.group(1))\n",
    "#             params['bw'] = int(match.group(2))\n",
    "#             params['ba'] = int(match.group(3))\n",
    "#             params['k'] = int(match.group(4))\n",
    "\n",
    "#     # MLPADC (no W-Reshape)\n",
    "#     # Example: MLPADC_bx8_bw8_ba8_k4\n",
    "#     if not model_type_str:\n",
    "#         match = re.fullmatch(r\"MLPADC_bx(\\d+)_bw(\\d+)_ba(\\d+)_k(\\d+)\", filename_key)\n",
    "#         if match:\n",
    "#             model_type_str = \"MLPADC\"\n",
    "#             params['bx'] = int(match.group(1))\n",
    "#             params['bw'] = int(match.group(2))\n",
    "#             params['ba'] = int(match.group(3))\n",
    "#             params['k'] = int(match.group(4))\n",
    "            \n",
    "#     # MLPQuant\n",
    "#     # Example: MLPQuant_bx8_bw8\n",
    "#     if not model_type_str:\n",
    "#         match = re.fullmatch(r\"MLPQuant_bx(\\d+)_bw(\\d+)\", filename_key)\n",
    "#         if match:\n",
    "#             model_type_str = \"MLPQuant\"\n",
    "#             params['bx'] = int(match.group(1))\n",
    "#             params['bw'] = int(match.group(2))\n",
    "\n",
    "#     # MLP_Baseline\n",
    "#     # Example: MLP_Baseline\n",
    "#     if not model_type_str:\n",
    "#         match = re.fullmatch(r\"MLP_Baseline\", filename_key)\n",
    "#         if match:\n",
    "#             model_type_str = \"MLP\"\n",
    "\n",
    "#     if not model_type_str:\n",
    "#         print(f\"Warning: Could not parse model type or params for key '{filename_key}'. Skipping.\")\n",
    "#         return None, None\n",
    "\n",
    "#     # Instantiate model\n",
    "#     model = None\n",
    "#     if model_type_str == \"MLP\":\n",
    "#         model = MLP()\n",
    "#     elif model_type_str == \"MLPADC\":\n",
    "#         model = MLPADC(**params)\n",
    "#     elif model_type_str == \"MLPQuant\":\n",
    "#         model = MLPQuant(**params)\n",
    "#     elif model_type_str == \"MLPADCAshift\":\n",
    "#         model = MLPADCAshift(**params)\n",
    "    \n",
    "#     if model is None:\n",
    "#         print(f\"Warning: Failed to instantiate model for key '{filename_key}' with parsed type '{model_type_str}'. Skipping.\")\n",
    "#         return None, None\n",
    "        \n",
    "#     # Return the instantiated model and the original key for display purposes\n",
    "#     return model, filename_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_and_params(filename_key):\n",
    "    \"\"\"\n",
    "    Parses the filename key to determine model type and parameters,\n",
    "    then instantiates the model.\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    model_type_str = None\n",
    "    \n",
    "    # The filename_key is the part of the filename like \"MLPADC_bx8_bw8_ba8_k4\"\n",
    "    # Order of regex matching is important: more specific patterns first.\n",
    "    # We use re.fullmatch to ensure the entire key string matches the pattern.\n",
    "\n",
    "    # MLPADCAshift+W-Reshape\n",
    "    # Example: MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.001\n",
    "    match = re.fullmatch(r\"MLPADCAshiftplusW-Reshape_ashift(True|False)_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)lk([\\d.]+)\", filename_key)\n",
    "    if match:\n",
    "        model_type_str = \"MLPADCAshift\"\n",
    "        params['ashift_enabled'] = match.group(1) == \"True\"\n",
    "        params['bx'] = int(match.group(2))\n",
    "        params['bw'] = int(match.group(3))\n",
    "        params['ba'] = int(match.group(4))\n",
    "        params['k'] = int(match.group(5))\n",
    "        # lk (lambda_kurtosis) is a training param, not model architecture\n",
    "        \n",
    "    # MLPADCAshift (no W-Reshape)\n",
    "    # Example: MLPADCAshift_ashiftTrue_bx8bw8ba8k4\n",
    "    if not model_type_str:\n",
    "        match = re.fullmatch(r\"MLPADCAshift_ashift(True|False)_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)\", filename_key)\n",
    "        if match:\n",
    "            model_type_str = \"MLPADCAshift\"\n",
    "            params['ashift_enabled'] = match.group(1) == \"True\"\n",
    "            params['bx'] = int(match.group(2))\n",
    "            params['bw'] = int(match.group(3))\n",
    "            params['ba'] = int(match.group(4))\n",
    "            params['k'] = int(match.group(5))\n",
    "\n",
    "    # MLPADC+W-Reshape\n",
    "    # Example: MLPADCplusW-Reshape_bx8bw8ba8k4lk0.001\n",
    "    if not model_type_str:\n",
    "        match = re.fullmatch(r\"MLPADCplusW-Reshape_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)lk([\\d.]+)\", filename_key)\n",
    "        if match:\n",
    "            model_type_str = \"MLPADC\"\n",
    "            params['bx'] = int(match.group(1))\n",
    "            params['bw'] = int(match.group(2))\n",
    "            params['ba'] = int(match.group(3))\n",
    "            params['k'] = int(match.group(4))\n",
    "\n",
    "    # MLPADC (no W-Reshape)\n",
    "    # Example: MLPADC_bx8bw8ba8k4\n",
    "    if not model_type_str:\n",
    "        match = re.fullmatch(r\"MLPADC_bx(\\d+)bw(\\d+)ba(\\d+)k(\\d+)\", filename_key)\n",
    "        if match:\n",
    "            model_type_str = \"MLPADC\"\n",
    "            params['bx'] = int(match.group(1))\n",
    "            params['bw'] = int(match.group(2))\n",
    "            params['ba'] = int(match.group(3))\n",
    "            params['k'] = int(match.group(4))\n",
    "            \n",
    "    # MLPQuant\n",
    "    # Example: MLPQuant_bx8_bw8\n",
    "    if not model_type_str:\n",
    "        match = re.fullmatch(r\"MLPQuant_bx(\\d+)_bw(\\d+)\", filename_key)\n",
    "        if match:\n",
    "            model_type_str = \"MLPQuant\"\n",
    "            params['bx'] = int(match.group(1))\n",
    "            params['bw'] = int(match.group(2))\n",
    "\n",
    "    # MLP_Baseline\n",
    "    # Example: MLP_Baseline\n",
    "    if not model_type_str:\n",
    "        match = re.fullmatch(r\"MLP_Baseline\", filename_key)\n",
    "        if match:\n",
    "            model_type_str = \"MLP\"\n",
    "\n",
    "    if not model_type_str:\n",
    "        print(f\"Warning: Could not parse model type or params for key '{filename_key}'. Skipping.\")\n",
    "        return None, None\n",
    "\n",
    "    # Instantiate model\n",
    "    model = None\n",
    "    if model_type_str == \"MLP\":\n",
    "        model = MLP()\n",
    "    elif model_type_str == \"MLPADC\":\n",
    "        model = MLPADC(**params)\n",
    "    elif model_type_str == \"MLPQuant\":\n",
    "        model = MLPQuant(**params)\n",
    "    elif model_type_str == \"MLPADCAshift\":\n",
    "        model = MLPADCAshift(**params)\n",
    "    \n",
    "    if model is None:\n",
    "        print(f\"Warning: Failed to instantiate model for key '{filename_key}' with parsed type '{model_type_str}'. Skipping.\")\n",
    "        return None, None\n",
    "        \n",
    "    # Return the instantiated model and the original key for display purposes\n",
    "    return model, filename_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 model weight file(s) to process.\n",
      "\n",
      "Processing file: model_MLPQuant_bx8_bw8_weights_20250506_230304.pth\n",
      "Successfully loaded model: MLPQuant_bx8_bw8 from model_MLPQuant_bx8_bw8_weights_20250506_230304.pth\n",
      "Saved weight distribution plot to: ./results/weight_distributions/weights_dist_MLPQuant_bx8_bw8_20250506_230304.png\n",
      "\n",
      "Processing file: model_MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.0005_weights_20250506_230304.pth\n",
      "Successfully loaded model: MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.0005 from model_MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.0005_weights_20250506_230304.pth\n",
      "Saved weight distribution plot to: ./results/weight_distributions/weights_dist_MLPADCAshiftplusW-Reshape_ashiftTrue_bx8bw8ba8k4lk0.0005_20250506_230304.png\n",
      "\n",
      "Processing file: model_MLPADCAshift_ashiftTrue_bx8_bw8_ba8_k4_weights_20250506_230304.pth\n",
      "Warning: Could not parse model type or params for key 'MLPADCAshift_ashiftTrue_bx8_bw8_ba8_k4'. Skipping.\n",
      "\n",
      "Processing file: model_MLPADC_bx8_bw8_ba8_k4_weights_20250506_230304.pth\n",
      "Warning: Could not parse model type or params for key 'MLPADC_bx8_bw8_ba8_k4'. Skipping.\n",
      "\n",
      "Processing file: model_MLP_Baseline_weights_20250506_230304.pth\n",
      "Successfully loaded model: MLP_Baseline from model_MLP_Baseline_weights_20250506_230304.pth\n",
      "Saved weight distribution plot to: ./results/weight_distributions/weights_dist_MLP_Baseline_20250506_230304.png\n",
      "\n",
      "Processing file: model_MLPADCplusW-Reshape_bx8bw8ba8k4lk0.0005_weights_20250506_230304.pth\n",
      "Successfully loaded model: MLPADCplusW-Reshape_bx8bw8ba8k4lk0.0005 from model_MLPADCplusW-Reshape_bx8bw8ba8k4lk0.0005_weights_20250506_230304.pth\n",
      "Saved weight distribution plot to: ./results/weight_distributions/weights_dist_MLPADCplusW-Reshape_bx8bw8ba8k4lk0.0005_20250506_230304.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_files = [f for f in os.listdir('/home/coder/project/results') if re.match(r\"model_.*_weights_.*\\.pth\", f)]\n",
    "\n",
    "\n",
    "print(f\"Found {len(weight_files)} model weight file(s) to process.\")\n",
    "\n",
    "for fname in weight_files:\n",
    "    print(f\"\\nProcessing file: {fname}\")\n",
    "    filepath = os.path.join('/home/coder/project/results', fname)\n",
    "    \n",
    "    # Extract model key and timestamp from filename\n",
    "    # Example: model_MLPADC_bx8_bw8_ba8_k4_weights_20231120_103045.pth\n",
    "    # filename_key will be \"MLPADC_bx8_bw8_ba8_k4\"\n",
    "    # file_timestamp will be \"20231120_103045\"\n",
    "    name_part_match = re.match(r\"model_(.*?)_weights_(\\d{8}_\\d{6})\\.pth\", fname)\n",
    "    if not name_part_match:\n",
    "        print(f\"Could not parse model key or timestamp from filename: '{fname}'. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    filename_key = name_part_match.group(1)\n",
    "    file_timestamp = name_part_match.group(2)\n",
    "\n",
    "    model, model_display_name = get_model_instance_and_params(filename_key)\n",
    "\n",
    "    if not model or not model_display_name:\n",
    "        continue # Error message already printed by get_model_instance_and_params\n",
    "\n",
    "    try:\n",
    "        # Load weights to CPU map_location by default for broader compatibility\n",
    "        model.load_state_dict(torch.load(filepath, map_location=torch.device('cpu')))\n",
    "        model.to(device) # Then move to the designated device if needed for model operations (eval is fine on CPU)\n",
    "        model.eval()\n",
    "        print(f\"Successfully loaded model: {model_display_name} from {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading state_dict for {fname}: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    layer_weights_data = []\n",
    "    layer_names = []\n",
    "    for name, param in model.named_parameters():\n",
    "        # We are interested in 'weight' parameters, typically from Linear layers or their custom equivalents.\n",
    "        # Filter for parameters that are likely main weights of layers (e.g., 'layers.0.weight', 'fc.weight')\n",
    "        # and are at least 2D (to avoid biases if they were named '...weight').\n",
    "        if param.requires_grad and \"weight\" in name and param.dim() >= 2:\n",
    "            layer_weights_data.append(param.data.cpu().numpy().flatten())\n",
    "            layer_names.append(name)\n",
    "    \n",
    "    if not layer_weights_data:\n",
    "        print(f\"No suitable weight layers found for model {model_display_name} from file {fname}.\")\n",
    "        continue\n",
    "\n",
    "    num_layers_with_weights = len(layer_weights_data)\n",
    "    \n",
    "    fig_height = max(5, 3 * num_layers_with_weights) \n",
    "    fig_width = 8 \n",
    "\n",
    "    # Use squeeze=False to ensure axes is always a 2D array for consistent indexing\n",
    "    fig, axes = plt.subplots(num_layers_with_weights, 1, figsize=(fig_width, fig_height), squeeze=False)\n",
    "    \n",
    "    fig.suptitle(f\"Weight Distributions for: {model_display_name}\\n(Source File Timestamp: {file_timestamp})\", fontsize=14)\n",
    "\n",
    "    for i in range(num_layers_with_weights):\n",
    "        ax = axes[i, 0] # Access subplot using [row, 0] due to squeeze=False and single column\n",
    "        weights_flat = layer_weights_data[i]\n",
    "        layer_name = layer_names[i]\n",
    "        \n",
    "        min_val, max_val = weights_flat.min(), weights_flat.max()\n",
    "        ax.hist(weights_flat, bins=50, alpha=0.75, color='cornflowerblue', edgecolor='black')\n",
    "        ax.set_title(f\"Layer: {layer_name} (Range: [{min_val:.2e}, {max_val:.2e}])\", fontsize=10)\n",
    "        ax.set_xlabel(\"Weight Value\", fontsize=9)\n",
    "        ax.set_ylabel(\"Frequency\", fontsize=9)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect for suptitle\n",
    "    \n",
    "    # Construct a unique plot filename using the original filename key and its timestamp\n",
    "    plot_savename = f\"weights_dist_{filename_key}_{file_timestamp}.png\"\n",
    "    plot_save_path = os.path.join(PLOTS_OUTPUT_DIR, plot_savename)\n",
    "    \n",
    "    try:\n",
    "        plt.savefig(plot_save_path)\n",
    "        print(f\"Saved weight distribution plot to: {plot_save_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving plot {plot_save_path}: {e}\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
